{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment 5 #\n",
        "### Due: Friday, November 17th to be submitted via Canvas by 11:59 pm ###\n",
        "### Total points: **65** ###"
      ],
      "metadata": {
        "id": "_0gfAbD1BRax"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Group 106\n",
        "- Zihao Zhu\n",
        "- Yolanda Ojeda"
      ],
      "metadata": {
        "id": "gZqfRIkLrNw4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q1: Support Vector Machines (10 points)\n",
        "\n",
        "In this question, we will explore support vector machines for the Spam Base dataset from the UCI repository."
      ],
      "metadata": {
        "id": "omOSpxMmBTQE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import make_scorer, accuracy_score\n",
        "from sklearn.model_selection import train_test_split, cross_val_score"
      ],
      "metadata": {
        "id": "0GbdHYxjLiok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 42"
      ],
      "metadata": {
        "id": "tVj75ETFMaUJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install ucimlrepo"
      ],
      "metadata": {
        "id": "26ixmQ9qT6z3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6a4bc77-f6b0-4b07-93ed-74a1ac2c15ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ucimlrepo\n",
            "  Downloading ucimlrepo-0.0.3-py3-none-any.whl (7.0 kB)\n",
            "Installing collected packages: ucimlrepo\n",
            "Successfully installed ucimlrepo-0.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from ucimlrepo import fetch_ucirepo\n",
        "# fetch dataset\n",
        "#spambase = fetch_ucirepo(id=94)\n",
        "\n",
        "df = pd.read_csv(\"spambase.data\", header=None)\n",
        "y = df[57]\n",
        "X = df.drop(columns=[57])\n",
        "\n",
        "# data (as pandas dataframes)\n",
        "#X = spambase.data.features\n",
        "#y = spambase.data.targets\n",
        "#print(\"Abstract:\", spambase.metadata['abstract'])\n",
        "#print(\"Number of instances:\", spambase.metadata['num_instances'])\n",
        "#print(\"Number of features:\", spambase.metadata['num_features'])\n",
        "#print(spambase.variables['name'])"
      ],
      "metadata": {
        "id": "DlQyfxg0YuB0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.head()"
      ],
      "metadata": {
        "id": "lmKGx3T8ZXci",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "outputId": "1440348a-c37d-427c-8d43-acc4fe8ad7ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     0     1     2    3     4     5     6     7     8     9   ...   47    48  \\\n",
              "0  0.00  0.64  0.64  0.0  0.32  0.00  0.00  0.00  0.00  0.00  ...  0.0  0.00   \n",
              "1  0.21  0.28  0.50  0.0  0.14  0.28  0.21  0.07  0.00  0.94  ...  0.0  0.00   \n",
              "2  0.06  0.00  0.71  0.0  1.23  0.19  0.19  0.12  0.64  0.25  ...  0.0  0.01   \n",
              "3  0.00  0.00  0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63  ...  0.0  0.00   \n",
              "4  0.00  0.00  0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63  ...  0.0  0.00   \n",
              "\n",
              "      49   50     51     52     53     54   55    56  \n",
              "0  0.000  0.0  0.778  0.000  0.000  3.756   61   278  \n",
              "1  0.132  0.0  0.372  0.180  0.048  5.114  101  1028  \n",
              "2  0.143  0.0  0.276  0.184  0.010  9.821  485  2259  \n",
              "3  0.137  0.0  0.137  0.000  0.000  3.537   40   191  \n",
              "4  0.135  0.0  0.135  0.000  0.000  3.537   40   191  \n",
              "\n",
              "[5 rows x 57 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e2e9db0e-74a5-45ca-befd-c79862e61e94\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>47</th>\n",
              "      <th>48</th>\n",
              "      <th>49</th>\n",
              "      <th>50</th>\n",
              "      <th>51</th>\n",
              "      <th>52</th>\n",
              "      <th>53</th>\n",
              "      <th>54</th>\n",
              "      <th>55</th>\n",
              "      <th>56</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.778</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>3.756</td>\n",
              "      <td>61</td>\n",
              "      <td>278</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.21</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.94</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.132</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.372</td>\n",
              "      <td>0.180</td>\n",
              "      <td>0.048</td>\n",
              "      <td>5.114</td>\n",
              "      <td>101</td>\n",
              "      <td>1028</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.06</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.71</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.23</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.25</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.143</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.276</td>\n",
              "      <td>0.184</td>\n",
              "      <td>0.010</td>\n",
              "      <td>9.821</td>\n",
              "      <td>485</td>\n",
              "      <td>2259</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.63</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.137</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.137</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>3.537</td>\n",
              "      <td>40</td>\n",
              "      <td>191</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.63</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.135</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.135</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>3.537</td>\n",
              "      <td>40</td>\n",
              "      <td>191</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 57 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e2e9db0e-74a5-45ca-befd-c79862e61e94')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e2e9db0e-74a5-45ca-befd-c79862e61e94 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e2e9db0e-74a5-45ca-befd-c79862e61e94');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-907516cc-dd73-416f-94c3-205bfe0167f6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-907516cc-dd73-416f-94c3-205bfe0167f6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-907516cc-dd73-416f-94c3-205bfe0167f6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 42\n",
        "y = y.to_numpy().squeeze()\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=seed)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "tukYZVbDZsG-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "a. (5 points) Implement the following function to train SVMs with a specified kernel type, hyper-parameter search space, and random state on the Spam Base dataset. Do hyper-parameter search over $C$ using [cross_val_score](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html), setting the number of folds to 5. After finding the best C, please use it to train the final model and return both the final model and the best C."
      ],
      "metadata": {
        "id": "1jdODxjI41xm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def search_best_svm(kernel, C_search_space, random_state):\n",
        "    best_score = -np.inf\n",
        "    best_C = None\n",
        "\n",
        "    for C in C_search_space:\n",
        "        # Initialize an SVM classifier with the specified kernel type, C value, and random state\n",
        "        model = SVC(kernel=kernel, C=C, random_state=random_state)  # Correct assignment\n",
        "\n",
        "        # Evaluate accuracy scores using 5-fold cross-validation scores\n",
        "        scores = cross_val_score(model, X_train, y_train, cv=5)\n",
        "\n",
        "        # Compute the average score and compare with the current best score to update the best C\n",
        "        score = np.mean(scores)\n",
        "        if score > best_score:\n",
        "            best_score = score\n",
        "            best_C = C\n",
        "        print(f\"C: {C} Avg Cross Val Score: {np.round(score, 4)}\")\n",
        "\n",
        "    print(f\"Best C: {best_C}\")\n",
        "\n",
        "    # Initialize the model using the specified kernel type, best C, and random state;\n",
        "    # and then fit the model using the training set\n",
        "    model = SVC(kernel=kernel, C=best_C, random_state=random_state)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    return model, best_C\n"
      ],
      "metadata": {
        "id": "K90sxpVK7mED"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "b. (3 points) Run the function you implemented above to train SVMs with the search space of $C$ being [$0.1, 1, 10, 100$], random state set to 42, with the following three popular kernels: (i) linear (ii) polynomial (iii) RBF (Gaussian). Evaluate your final models on the test set and report their accuracies."
      ],
      "metadata": {
        "id": "IZ_MU9Fl6EIn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the C search space and kernels\n",
        "C_search_space = [0.1, 1, 10, 100]\n",
        "kernels = ['linear', 'poly', 'rbf']\n",
        "\n",
        "# Train and evaluate models for each kernel\n",
        "for kernel in kernels:\n",
        "    model, best_C = search_best_svm(kernel, C_search_space, random_state=42)\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"Kernel: {kernel}, Best C: {best_C}, Test Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQrAmamr_MTh",
        "outputId": "aa971e76-ff1f-464a-f7c9-f6be1523865a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "C: 0.1 Avg Cross Val Score: 0.9214\n",
            "C: 1 Avg Cross Val Score: 0.9264\n",
            "C: 10 Avg Cross Val Score: 0.9283\n",
            "C: 100 Avg Cross Val Score: 0.9268\n",
            "Best C: 10\n",
            "Kernel: linear, Best C: 10, Test Accuracy: 0.9283\n",
            "C: 0.1 Avg Cross Val Score: 0.6895\n",
            "C: 1 Avg Cross Val Score: 0.7594\n",
            "C: 10 Avg Cross Val Score: 0.8428\n",
            "C: 100 Avg Cross Val Score: 0.8957\n",
            "Best C: 100\n",
            "Kernel: poly, Best C: 100, Test Accuracy: 0.9125\n",
            "C: 0.1 Avg Cross Val Score: 0.896\n",
            "C: 1 Avg Cross Val Score: 0.9243\n",
            "C: 10 Avg Cross Val Score: 0.9243\n",
            "C: 100 Avg Cross Val Score: 0.9123\n",
            "Best C: 10\n",
            "Kernel: rbf, Best C: 10, Test Accuracy: 0.9354\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "c. (2 points) Train a logistic regression model using the training set. Compare its performance with that of the SVMs trained above."
      ],
      "metadata": {
        "id": "pCxwqenL6nZ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Logistic Regression model\n",
        "log_reg = LogisticRegression(random_state=42)\n",
        "log_reg.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate the model\n",
        "y_pred_log_reg = log_reg.predict(X_test)\n",
        "accuracy_log_reg = accuracy_score(y_test, y_pred_log_reg)\n",
        "print(f\"Logistic Regression Test Accuracy: {accuracy_log_reg:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iIbwi8_pFzxz",
        "outputId": "b74570ad-08ef-4cb7-fda7-9bd100788e5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Test Accuracy: 0.9223\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bc9ca1b5"
      },
      "source": [
        "# Question 2 : Ensemble Methods for Classification (25 pts)\n",
        "\n",
        "In this question, we will compare the performances of different ensemble methods for classification problems: [Bagging](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html), [AdaBoost](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html), [Random Forest](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) and [XGBoost](https://xgboost.readthedocs.io/en/stable/python/python_api.html) classifiers.\n",
        "\n",
        "We will look at the [GiveMeSomeCredit](https://www.kaggle.com/c/GiveMeSomeCredit) dataset for this question. The dataset is extremely large so for this question we will only consider a subset which has been provided along with the notebook for this assignment. The dataset has already been split into train and test sets.\n",
        "\n",
        "The task is to predict the probability that someone will experience financial distress in the next two years."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a93b913f",
        "outputId": "e9780d59-b160-4cee-8bcf-badd3cd345ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c87f6fc1-a137-4223-8075-33a048538c25\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c87f6fc1-a137-4223-8075-33a048538c25\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving hw5_data.csv to hw5_data.csv\n"
          ]
        }
      ],
      "source": [
        "# Only use this code block if you are using Google Colab.\n",
        "# If you are using Jupyter Notebook, please ignore this code block. You can directly upload the file to your Jupyter Notebook file systems.\n",
        "from google.colab import files\n",
        "\n",
        "## It will prompt you to select a local file. Click on “Choose Files” then select and upload the file.\n",
        "## Wait for the file to be 100% uploaded. You should see the name of the file once Colab has uploaded it.\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1a2bac93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "190a0e59-ade3-4160-aa8a-fbb0c43cf350"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   SeriousDlqin2yrs  RevolvingUtilizationOfUnsecuredLines  age  \\\n",
              "0                 0                              0.571373   66   \n",
              "1                 0                              0.233999   56   \n",
              "2                 0                              0.299270   33   \n",
              "3                 0                              0.032165   41   \n",
              "4                 0                              0.050591   36   \n",
              "\n",
              "   NumberOfTime30-59DaysPastDueNotWorse  DebtRatio  MonthlyIncome  \\\n",
              "0                                     0   0.430620         9274.0   \n",
              "1                                     0   0.257380         5656.0   \n",
              "2                                     0   0.114575         4747.0   \n",
              "3                                     0   0.308326         8490.0   \n",
              "4                                     0   0.862627         3333.0   \n",
              "\n",
              "   NumberOfOpenCreditLinesAndLoans  NumberOfTimes90DaysLate  \\\n",
              "0                               10                        0   \n",
              "1                               12                        0   \n",
              "2                                8                        0   \n",
              "3                                8                        0   \n",
              "4                                8                        0   \n",
              "\n",
              "   NumberRealEstateLoansOrLines  NumberOfTime60-89DaysPastDueNotWorse  \\\n",
              "0                             1                                     0   \n",
              "1                             0                                     0   \n",
              "2                             0                                     0   \n",
              "3                             1                                     0   \n",
              "4                             2                                     0   \n",
              "\n",
              "   NumberOfDependents  \n",
              "0                 0.0  \n",
              "1                 0.0  \n",
              "2                 3.0  \n",
              "3                 0.0  \n",
              "4                 0.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6c4d4fc5-ef90-4bef-89c8-73aaea154b64\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SeriousDlqin2yrs</th>\n",
              "      <th>RevolvingUtilizationOfUnsecuredLines</th>\n",
              "      <th>age</th>\n",
              "      <th>NumberOfTime30-59DaysPastDueNotWorse</th>\n",
              "      <th>DebtRatio</th>\n",
              "      <th>MonthlyIncome</th>\n",
              "      <th>NumberOfOpenCreditLinesAndLoans</th>\n",
              "      <th>NumberOfTimes90DaysLate</th>\n",
              "      <th>NumberRealEstateLoansOrLines</th>\n",
              "      <th>NumberOfTime60-89DaysPastDueNotWorse</th>\n",
              "      <th>NumberOfDependents</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.571373</td>\n",
              "      <td>66</td>\n",
              "      <td>0</td>\n",
              "      <td>0.430620</td>\n",
              "      <td>9274.0</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0.233999</td>\n",
              "      <td>56</td>\n",
              "      <td>0</td>\n",
              "      <td>0.257380</td>\n",
              "      <td>5656.0</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0.299270</td>\n",
              "      <td>33</td>\n",
              "      <td>0</td>\n",
              "      <td>0.114575</td>\n",
              "      <td>4747.0</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0.032165</td>\n",
              "      <td>41</td>\n",
              "      <td>0</td>\n",
              "      <td>0.308326</td>\n",
              "      <td>8490.0</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0.050591</td>\n",
              "      <td>36</td>\n",
              "      <td>0</td>\n",
              "      <td>0.862627</td>\n",
              "      <td>3333.0</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6c4d4fc5-ef90-4bef-89c8-73aaea154b64')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6c4d4fc5-ef90-4bef-89c8-73aaea154b64 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6c4d4fc5-ef90-4bef-89c8-73aaea154b64');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b84054af-31c9-4be9-af9c-c1135716b830\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b84054af-31c9-4be9-af9c-c1135716b830')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b84054af-31c9-4be9-af9c-c1135716b830 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv('hw5_data.csv')\n",
        "data.drop(data.columns[data.columns.str.contains('unnamed',case = False)],axis = 1, inplace = True)\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fb34060d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc4926d5-8f01-4dc1-9854-132a8b0b786f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: (3750, 10) (3750,)\n",
            "test: (1250, 10) (1250,)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "y = data['SeriousDlqin2yrs']\n",
        "X = data.drop(['SeriousDlqin2yrs'],axis=1)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 7)\n",
        "\n",
        "print('train:',X_train.shape, y_train.shape)\n",
        "print('test:',X_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "90d16082"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import (train_test_split,GridSearchCV)\n",
        "from sklearn.metrics import (accuracy_score,roc_auc_score)\n",
        "from sklearn.ensemble import (RandomForestClassifier,GradientBoostingClassifier,AdaBoostClassifier)\n",
        "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from time import time\n",
        "import xgboost as xgb\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "420aeb16"
      },
      "outputs": [],
      "source": [
        "columns_list = list(X.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f40f9107"
      },
      "source": [
        "a. (2.5 pts) Fit a Decision Tree Classifier with random_state = 14 for this classification problem. Report the accuracy_score and roc_auc_score on the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "45de59e6"
      },
      "outputs": [],
      "source": [
        "def fit_classifier(clf):\n",
        "  # Fit the classifier on the training set\n",
        "  ### START CODE ###\n",
        "  clf.fit(X_train, y_train)\n",
        "  ### END CODE ###\n",
        "  return clf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_classifier(clf, X_test, y_test):\n",
        "  # Compute the accuracy_score, and roc_auc_score on the test set\n",
        "  ### START CODE ###\n",
        "  y_pred = clf.predict(X_test)\n",
        "  y_pred_proba = clf.predict_proba(X_test)[:, 1]\n",
        "\n",
        "  acc_score = accuracy_score(y_test, y_pred)\n",
        "  auc_score = roc_auc_score(y_test, y_pred_proba)\n",
        "  ### END CODE ###\n",
        "  print(\"Accuracy_score: {}, ROC_AUC_score: {}\".format(acc_score, auc_score))"
      ],
      "metadata": {
        "id": "yZfiYRKtHJQ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9a436542",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f23430c-7710-4d95-f765-03ce0b7110e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree\n",
            "Accuracy_score: 0.888, ROC_AUC_score: 0.5854582176218127\n"
          ]
        }
      ],
      "source": [
        "print(\"Decision Tree\")\n",
        "# Initialize your decision tree classifier\n",
        "### START CODE ###\n",
        "dt_clf = DecisionTreeClassifier(random_state=14)\n",
        "### END CODE ###\n",
        "\n",
        "dt_clf = fit_classifier(dt_clf)\n",
        "evaluate_classifier(dt_clf, X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6d360a99"
      },
      "source": [
        "b. (2.5 pts) Create a [Bagging](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html) of 25 classifiers (i.e, n_estimators=25) with random_state=14. Please use Decision Tree Classifier with random_state=14 as the base classifier. Report accuracy_score and roc_auc_score on the test data for this emsemble classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "239c9c3c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a8d0a90-2936-40ac-8907-c168ee84ecd0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging of Decesion Trees\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy_score: 0.9256, ROC_AUC_score: 0.7857106791214341\n"
          ]
        }
      ],
      "source": [
        "print(\"Bagging of Decesion Trees\")\n",
        "# Initialize your bagging classifier\n",
        "### START CODE ###\n",
        "bag_clf = BaggingClassifier(\n",
        "    base_estimator=DecisionTreeClassifier(random_state=14),\n",
        "    n_estimators=25,\n",
        "    random_state=14\n",
        ")\n",
        "### END CODE ###\n",
        "\n",
        "bag_clf = fit_classifier(bag_clf)\n",
        "evaluate_classifier(bag_clf, X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34225ee3"
      },
      "source": [
        "c. (5 pts) In this question, you will fit a [Random Forest](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) model on the training data for this classification task.\n",
        "\n",
        "1. First, please find the best parameters (including *n_estimators*, *max_features* and *criterion*) using [GridSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html). Report the optimal parameters obtained by GridSearch.\n",
        "2. Fit a model using the best parameters, and report the [confusion matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html) and [roc_auc_score](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score) on test data."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def grid_search_for_classifier(clf, param_grid, X_train, y_train):\n",
        "  # Grid search\n",
        "  grid_search = GridSearchCV(clf, param_grid=param_grid)\n",
        "\n",
        "  # Conduct grid search using the training set (1 line of code only)\n",
        "  ### START CODE ###\n",
        "  grid_search.fit(X_train, y_train)\n",
        "  ### END CODE ###\n",
        "  print(grid_search.best_params_)\n",
        "\n",
        "  # Set the best paramters for your clf (1 line of code only)\n",
        "  ### START CODE ###\n",
        "  clf.set_params(**grid_search.best_params_)\n",
        "  ### END CODE ###\n",
        "  return clf"
      ],
      "metadata": {
        "id": "R9E7sMGt2goM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_evaluate_classifier(clf, X_train, y_train, X_test, y_test):\n",
        "  t0 = time()\n",
        "  # Fit your classifier on the training set\n",
        "  ### START CODE ###\n",
        "  clf.fit(X_train, y_train)\n",
        "  ### END CODE ###\n",
        "  print(\"training time\", round(time()-t0, 3), \"s\")\n",
        "\n",
        "  t0 = time()\n",
        "  y_pred = clf.predict(X_test)\n",
        "  print(\"predict time\", round(time()-t0, 3), \"s\")\n",
        "\n",
        "  print(\"Confusion matrix: \")\n",
        "  # Print the confusion matrix computed from the test set (1 line of code only)\n",
        "  ### START CODE ###\n",
        "  print(confusion_matrix(y_test, y_pred))\n",
        "  ### END CODE ###\n",
        "\n",
        "\n",
        "  ### START CODE ###\n",
        "  y_pred_proba = clf.predict_proba(X_test)[:, 1]\n",
        "  acc_score = accuracy_score(y_test, y_pred)\n",
        "  auc_score = roc_auc_score(y_test, y_pred_proba)\n",
        "  ### END CODE ###\n",
        "\n",
        "  print(\"Accuracy: {}, AUC_ROC: {}\".format(acc_score, auc_score))\n",
        "  return clf"
      ],
      "metadata": {
        "id": "4UyA2_rB2gG9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6bfb9542",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2ddf941e-b7e0-4cdd-a68f-5f0690767e23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'criterion': 'entropy', 'max_features': 1, 'n_estimators': 100, 'random_state': 17}\n",
            "training time 0.404 s\n",
            "predict time 0.026 s\n",
            "Confusion matrix: \n",
            "[[1162    3]\n",
            " [  82    3]]\n",
            "Accuracy: 0.932, AUC_ROC: 0.8375612219136582\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(criterion='entropy', max_features=1, random_state=17)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, max_features=1, random_state=17)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, max_features=1, random_state=17)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "param_grid = {\"n_estimators\": [1, 10, 50, 100],\n",
        "              \"max_features\": [1, 5, 10, \"auto\"],\n",
        "              \"criterion\": ['gini','entropy'],\n",
        "              \"random_state\": [17]}\n",
        "\n",
        "# Initialize your random forest classifier\n",
        "### START CODE ###\n",
        "rf_clf = RandomForestClassifier(random_state=14)\n",
        "### END CODE ###\n",
        "rf_clf = grid_search_for_classifier(rf_clf, param_grid, X_train, y_train)\n",
        "train_and_evaluate_classifier(rf_clf, X_train, y_train, X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "314c313b"
      },
      "source": [
        "d. (10 pts) This time, let us use [AdaBoost](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html#sklearn.ensemble.AdaBoostClassifier) and [XGBoost](https://xgboost.readthedocs.io/en/stable/python/python_api.html) for the same task. For AdaBoost and XGBoost, please respectively find the best parameters (including *n_estimators, learning_rate*); fit your model using the best parameters, and report the confusion matrix and roc_auc_score on test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3222ef25"
      },
      "outputs": [],
      "source": [
        "param_grid = {\"n_estimators\": [10, 100],\n",
        "          \"learning_rate\": [0.01, 0.1, 0.5],\n",
        "          \"random_state\": [17]\n",
        "          }"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize your AdaBoost classifier\n",
        "### START CODE ###\n",
        "ab_clf = AdaBoostClassifier(random_state=17)\n",
        "### END CODE ###\n",
        "ab_clf = grid_search_for_classifier(ab_clf, param_grid, X_train, y_train)\n",
        "train_and_evaluate_classifier(ab_clf, X_train, y_train, X_test, y_test)"
      ],
      "metadata": {
        "id": "bp4Ekjpy1cGw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "outputId": "89951bd2-daef-41fc-ce0b-a37610b570d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'learning_rate': 0.1, 'n_estimators': 100, 'random_state': 17}\n",
            "training time 0.474 s\n",
            "predict time 0.032 s\n",
            "Confusion matrix: \n",
            "[[1153   12]\n",
            " [  72   13]]\n",
            "Accuracy: 0.9328, AUC_ROC: 0.8390254986114618\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AdaBoostClassifier(learning_rate=0.1, n_estimators=100, random_state=17)"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>AdaBoostClassifier(learning_rate=0.1, n_estimators=100, random_state=17)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AdaBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>AdaBoostClassifier(learning_rate=0.1, n_estimators=100, random_state=17)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize your XGBoost classifier\n",
        "### START CODE ###\n",
        "xgb_clf = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
        "### END CODE ###\n",
        "xgb_clf = grid_search_for_classifier(xgb_clf, param_grid, X_train, y_train)\n",
        "train_and_evaluate_classifier(xgb_clf, X_train, y_train, X_test, y_test)"
      ],
      "metadata": {
        "id": "Hv0p1mZh2CqA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "outputId": "744162e2-3c33-4355-bfa1-ca429583efc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'learning_rate': 0.01, 'n_estimators': 100, 'random_state': 17}\n",
            "training time 0.133 s\n",
            "predict time 0.006 s\n",
            "Confusion matrix: \n",
            "[[1163    2]\n",
            " [  84    1]]\n",
            "Accuracy: 0.9312, AUC_ROC: 0.8267962635698057\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric='logloss',\n",
              "              feature_types=None, gamma=None, grow_policy=None,\n",
              "              importance_type=None, interaction_constraints=None,\n",
              "              learning_rate=0.01, max_bin=None, max_cat_threshold=None,\n",
              "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
              "              max_leaves=None, min_child_weight=None, missing=nan,\n",
              "              monotone_constraints=None, multi_strategy=None, n_estimators=100,\n",
              "              n_jobs=None, num_parallel_tree=None, random_state=17, ...)"
            ],
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
              "              feature_types=None, gamma=None, grow_policy=None,\n",
              "              importance_type=None, interaction_constraints=None,\n",
              "              learning_rate=0.01, max_bin=None, max_cat_threshold=None,\n",
              "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
              "              max_leaves=None, min_child_weight=None, missing=nan,\n",
              "              monotone_constraints=None, multi_strategy=None, n_estimators=100,\n",
              "              n_jobs=None, num_parallel_tree=None, random_state=17, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
              "              feature_types=None, gamma=None, grow_policy=None,\n",
              "              importance_type=None, interaction_constraints=None,\n",
              "              learning_rate=0.01, max_bin=None, max_cat_threshold=None,\n",
              "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
              "              max_leaves=None, min_child_weight=None, missing=nan,\n",
              "              monotone_constraints=None, multi_strategy=None, n_estimators=100,\n",
              "              n_jobs=None, num_parallel_tree=None, random_state=17, ...)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6bc87cd"
      },
      "source": [
        "f. (5 pts) Compare the performance of decision tree from part a) with the ensemble methods. Briefly explain which of the three ensemble methods performed better and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer**:\n",
        "\n",
        "\n",
        "As the previous result shows, the Decision Tree achieved an accuracy of 88.8% and an ROC-AUC score of 58.5%. When compared to ensemble methods, the Bagging of Decision Trees showed a substantial improvement with an accuracy of 92.56% and an ROC-AUC score of 78.57%. The Bagging ensemble method combines multiple decision trees to improve overall performance. The Random Forest, a variant of bagging, further enhanced the results with an accuracy of 93.28% and an ROC-AUC score of 83.90%.  Higher accuracy indicates a better overall performance of the model. AUC is a measure of a model's ability to distinguish between classes. A higher ROC AUC score suggests that the model is better at classifying positive and negative cases. The confusion matrix also shows the number of true positive, true negative, false positive, and false negative predictions. which the performance in terms of different types of errors in the three ensemble methods are realtively good in classifying.\n",
        "\n",
        "The superior performance of ensemble methods, especially Bagging and Random Forest, can be attributed to their ability to mitigate overfitting by aggregating the predictions of multiple base learners. By combining diverse decision trees, these methods capture a broader range of patterns in the data, leading to improved generalization on unseen instances. The ensemble methods excel in handling complex relationships within the dataset, resulting in better predictive performance compared to a standalone Decision Tree. Among the ensemble methods, Random Forest demonstrated the highest accuracy and ROC-AUC score, indicating its effectiveness in this classification task."
      ],
      "metadata": {
        "id": "yquU4YrIJD1k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q3: CatBoost (10 points)"
      ],
      "metadata": {
        "id": "jZXTR1tM7yBp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this question you will learn about a boosting algorithm known as **CatBoost**. Please go through the two videos specified below to get a better understanding of the CatBoost algorithm and answer the questions that follow.\n",
        "\n",
        "[Part-1](https://www.youtube.com/watch?v=KXOTSkPL2X4&ab_channel=StatQuestwithJoshStarmer)\n",
        "[Part - 2](https://www.youtube.com/watch?v=3Bg2XRFOTzg&t=242s&ab_channel=StatQuestwithJoshStarmer)\n",
        "\n",
        "\n",
        "\n",
        "a. **(5 points)** Briefly explain Ordered Target Encoding. What challenge does it try to address?\n",
        "\n",
        "b. **(5 points)** Briefly describe the main advantages and disadvantages of CatBoost as compared to XGBoost."
      ],
      "metadata": {
        "id": "3zcExque_yso"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer**:\n",
        "a) Ordered Target Encoding is a technique used in feature engineering for machine learning, particularly for handling categorical variables. It addresses a common challenge in dealing with categorical data: how to effectively encode these categories into numerical values that can be used in machine learning algorithms, especially when there are many categories or when the categories have an inherent order that might be significant for the prediction task.\n",
        "\n",
        "The primary challenge that Ordered Target Encoding tries to address is the efficient and meaningful encoding of categorical variables, especially when:\n",
        "\n",
        "High Cardinality: Traditional encoding methods like One-Hot Encoding can lead to a huge increase in dataset dimensions (many new columns) when dealing with categorical variables having many categories (high cardinality). This can increase computational complexity and may lead to overfitting.\n",
        "\n",
        "Inherent Order: When the categorical variable has an inherent order that is relevant to the target variable, Ordered Target Encoding can capture this relationship more effectively than methods that treat each category as completely independent.\n",
        "\n",
        "Overfitting with Simple Target Encoding: While simple target encoding can capture the relationship between categorical features and the target variable, it can easily overfit the training data, especially with small datasets or categories with few observations. Ordered Target Encoding addresses this by incorporating methods to reduce overfitting.\n",
        "\n",
        "\n",
        "b) CatBoost and XGBoost are both powerful gradient boosting libraries with distinct advantages and disadvantages. CatBoost stands out for its efficient handling of categorical features, eliminating the need for one-hot encoding and reducing preprocessing complexities. It also offers built-in cross-validation and robustness to overfitting, thanks to internal regularization techniques. However, CatBoost may have a slightly longer training time, especially on smaller datasets, and its community and documentation might not be as extensive as XGBoost.\n",
        "\n",
        "On the other hand, XGBoost boasts widespread adoption, a large and active community, and flexibility in regularization parameters, making it a reliable and well-supported choice. It excels in speed, particularly on smaller to medium-sized datasets, and provides efficient GPU support, though not as optimized as CatBoost. However, XGBoost requires explicit handling of categorical features through one-hot encoding, leading to increased memory usage and potentially longer preprocessing times. Choosing between CatBoost and XGBoost depends on the specific needs of the dataset, with CatBoost being advantageous for categorical feature-rich data, while XGBoost might be preferable for its speed and well-established community when dealing with other types of datasets."
      ],
      "metadata": {
        "id": "eAAVM7nXu8H3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q4: Convolutional Neural Network (20 points)\n",
        "In this question, we will continue our exercise on the SVHN classification task from the previous homework, but this time we will be using Convolutional Neural Networks."
      ],
      "metadata": {
        "id": "FTFRT23o76A2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "lW0odgzmXUU_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 42\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "os.environ['PYTHONHASHSEED'] = str(seed)"
      ],
      "metadata": {
        "id": "Dr0KdJ2LrCCV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform=torchvision.transforms.Compose([\n",
        "        torchvision.transforms.ToTensor(),\n",
        "        torchvision.transforms.Normalize((0.4376821, 0.4437697, 0.47280442), (0.19803012, 0.20101562, 0.19703614))\n",
        "        ])\n",
        "\n",
        "train_dataset = torchvision.datasets.SVHN(root='.', split='train', transform=transform, download=True)\n",
        "test_dataset = torchvision.datasets.SVHN(root='.', split='test', transform=transform, download=True)"
      ],
      "metadata": {
        "id": "oBCdEj-_0tkS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18596955-b640-48c2-9564-eb489d36e17a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://ufldl.stanford.edu/housenumbers/train_32x32.mat to ./train_32x32.mat\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 182040794/182040794 [00:11<00:00, 16384108.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://ufldl.stanford.edu/housenumbers/test_32x32.mat to ./test_32x32.mat\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 64275384/64275384 [00:02<00:00, 26013566.15it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_num = int(len(train_dataset) * 0.8)\n",
        "val_num = len(train_dataset) - train_num\n",
        "# Randomly split the training dataset into training dataset and validation dataset\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [train_num, val_num])\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=256, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False)"
      ],
      "metadata": {
        "id": "iLn4YKK90vjo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "a. (10 points) Build a convolutional neural network with the following sequential configuration. If not specified, please use the default setting of torch.nn.Conv2d. The output of the convolution layers will be fed into a fully-connected MLP. Then train the model with Adam optimizer (lr=1e-3) for 10 epochs. You should be able to achieve test accuracy of over 85%.\n",
        "\n",
        "\n",
        "\n",
        "> Layer 1\n",
        "*   2d convolution (# input channel=3, # output channel=16, kernel size=3, padding=1)\n",
        "*   2d batch normalization\n",
        "*   Relu activation\n",
        "\n",
        "> Pool 1\n",
        "*   2d max pooling (kernel size=2)\n",
        "\n",
        "> Layer 2\n",
        "*   2d convolution (# output channel=16, kernel size=3, padding=1)\n",
        "*   2d batch normalization\n",
        "*   Relu activation\n",
        "\n",
        "> Pool 2\n",
        "*   2d max pooling (kernel size=2)\n",
        "\n",
        "> Layer 3\n",
        "*   2d convolution (# output channel=32, kernel size=3, padding=1)\n",
        "*   2d batch normalization\n",
        "*   Relu activation\n",
        "\n",
        "> Pool 3\n",
        "*   2d max pooling (kernel size=2)\n",
        "\n",
        "References:\n",
        "\n",
        "*   https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html\n",
        "*   https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html\n",
        "*   https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html\n",
        "*   https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "RFUXsbsqjoCw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self, pool=True):\n",
        "        super(CNN, self).__init__()\n",
        "        self.pool = pool\n",
        "\n",
        "        # Create convolutional layers\n",
        "        ### START CODE ###\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(16, 16, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=2)\n",
        "        ### END CODE ###\n",
        "\n",
        "        # Create fully connected layers (nn.Linear)\n",
        "        if self.pool:\n",
        "            self.mlp1 = nn.Linear(32*4*4, 50)\n",
        "        else:\n",
        "            self.mlp1 = nn.Linear(32*32*32, 50)\n",
        "\n",
        "        self.mlp2 = nn.Linear(50, 50)\n",
        "        self.mlp3 = nn.Linear(50, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer1(x)\n",
        "        if self.pool:\n",
        "            x = self.pool1(x)\n",
        "\n",
        "        x = self.layer2(x)\n",
        "        if self.pool:\n",
        "            x = self.pool2(x)\n",
        "\n",
        "        x = self.layer3(x)\n",
        "        if self.pool:\n",
        "            x = self.pool3(x)\n",
        "        x = x.reshape(x.shape[0], -1)\n",
        "\n",
        "        x = F.relu(self.mlp1(x))\n",
        "        x = F.relu(self.mlp2(x))\n",
        "        x = self.mlp3(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "M8OcO88V01Rr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, loader, optimizer):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    total_num = 0\n",
        "    for data, target in tqdm(loader):\n",
        "        out = model(data)\n",
        "        # Calculate loss based on model output and target\n",
        "        loss = F.nll_loss(F.log_softmax(out, dim=1), target)\n",
        "\n",
        "        # Use the optimizer to perform backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        batch_size = len(target)\n",
        "        total_loss += loss.item() * batch_size\n",
        "        total_num += batch_size\n",
        "    avg_loss = total_loss / total_num\n",
        "    return avg_loss\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval(model, loader):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    total_correct = 0\n",
        "    total_num = 0\n",
        "    for data, target in tqdm(loader):\n",
        "        out = model(data)\n",
        "        # Calculate loss based on model output and target\n",
        "        loss = F.nll_loss(F.log_softmax(out, dim=1), target)\n",
        "\n",
        "        # Get model's prediction\n",
        "        pred = torch.argmax(out, dim=1)\n",
        "\n",
        "        # Count number of correct predictions\n",
        "        correct = accuracy_score(target, pred, normalize=False)\n",
        "\n",
        "        total_correct += correct\n",
        "        batch_size = len(target)\n",
        "        total_loss += loss.item() * batch_size\n",
        "        total_num += batch_size\n",
        "    avg_loss = total_loss / total_num\n",
        "    acc = total_correct / total_num\n",
        "    return avg_loss, acc"
      ],
      "metadata": {
        "id": "Ygrxekov097w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = CNN(pool=True)\n",
        "optimizer = torch.optim.Adam(model1.parameters(), lr=1e-3)\n",
        "best_acc = -np.inf\n",
        "epochs = 10\n",
        "for e in range(1, epochs + 1):\n",
        "    train_loss = train(model1, train_loader, optimizer)\n",
        "    val_loss, val_acc = eval(model1, val_loader)\n",
        "    if val_acc > best_acc:\n",
        "        best_acc = val_acc\n",
        "        best_model1 = model1\n",
        "    print(f\"Epoch: {e} Train Loss: {train_loss} Val Loss: {val_loss} Val Acc: {val_acc}\")"
      ],
      "metadata": {
        "id": "aET_5IqXDsC1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4367701d-9b6a-44aa-dffe-6addc44ce9b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 229/229 [01:07<00:00,  3.40it/s]\n",
            "100%|██████████| 58/58 [00:08<00:00,  6.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 Train Loss: 1.22839825788198 Val Loss: 0.647812260749592 Val Acc: 0.8073983073983074\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 229/229 [01:10<00:00,  3.27it/s]\n",
            "100%|██████████| 58/58 [00:10<00:00,  5.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 2 Train Loss: 0.5592806533471013 Val Loss: 0.5003044925001583 Val Acc: 0.8536718536718537\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 229/229 [01:04<00:00,  3.56it/s]\n",
            "100%|██████████| 58/58 [00:09<00:00,  5.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 3 Train Loss: 0.4593943901105135 Val Loss: 0.4746085552693455 Val Acc: 0.8582446082446082\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 229/229 [01:03<00:00,  3.58it/s]\n",
            "100%|██████████| 58/58 [00:09<00:00,  5.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 4 Train Loss: 0.41120777591565866 Val Loss: 0.42906942453877117 Val Acc: 0.8735326235326235\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 229/229 [01:03<00:00,  3.60it/s]\n",
            "100%|██████████| 58/58 [00:10<00:00,  5.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 5 Train Loss: 0.376636562444236 Val Loss: 0.407136069334598 Val Acc: 0.881040131040131\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 229/229 [01:04<00:00,  3.56it/s]\n",
            "100%|██████████| 58/58 [00:09<00:00,  5.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 6 Train Loss: 0.3525809457883647 Val Loss: 0.4136648689206754 Val Acc: 0.8751706251706252\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 229/229 [01:04<00:00,  3.57it/s]\n",
            "100%|██████████| 58/58 [00:10<00:00,  5.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 7 Train Loss: 0.33502779737103466 Val Loss: 0.3914568663871975 Val Acc: 0.8840431340431341\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 229/229 [01:03<00:00,  3.61it/s]\n",
            "100%|██████████| 58/58 [00:10<00:00,  5.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 8 Train Loss: 0.31703089203619733 Val Loss: 0.3720417320687622 Val Acc: 0.8904586404586404\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 229/229 [01:04<00:00,  3.56it/s]\n",
            "100%|██████████| 58/58 [00:09<00:00,  5.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 9 Train Loss: 0.3009738132185969 Val Loss: 0.3756331554648331 Val Acc: 0.8910728910728911\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 229/229 [01:03<00:00,  3.62it/s]\n",
            "100%|██████████| 58/58 [00:09<00:00,  5.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 Train Loss: 0.29225769216071906 Val Loss: 0.37330560991502415 Val Acc: 0.891960141960142\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_, test_acc = eval(best_model1, test_loader)\n",
        "print(f\"Test accuracy: {np.round(test_acc, 3)}\")"
      ],
      "metadata": {
        "id": "A7Za_DdlDwJX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0b06bd8-e88b-4fd7-df08-ed854b494e17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 102/102 [00:17<00:00,  5.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.889\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "b. (5 points) Use torch-summary to print a summary of the model. The number of parameters should be less than the one of the MLP we trained in the previous homework. Why does it have less number of parameters but have higher accuracy?\n",
        "\n",
        "Reference\n",
        "*   https://pypi.org/project/torch-summary/\n"
      ],
      "metadata": {
        "id": "xLAnNsjsnRpK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch-summary"
      ],
      "metadata": {
        "id": "tkuRsoNxR8dX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcd8ac52-c5e5-4ece-cc05-af532a01bcae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch-summary\n",
            "  Downloading torch_summary-1.4.5-py3-none-any.whl (16 kB)\n",
            "Installing collected packages: torch-summary\n",
            "Successfully installed torch-summary-1.4.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "\n",
        "summary(best_model1, (3, 32, 32))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFKVY1HoPFDw",
        "outputId": "22ffa489-3d77-42f1-f9d6-3e6c254a2049"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==========================================================================================\n",
            "Layer (type:depth-idx)                   Output Shape              Param #\n",
            "==========================================================================================\n",
            "├─Sequential: 1-1                        [-1, 16, 32, 32]          --\n",
            "|    └─Conv2d: 2-1                       [-1, 16, 32, 32]          448\n",
            "|    └─BatchNorm2d: 2-2                  [-1, 16, 32, 32]          32\n",
            "|    └─ReLU: 2-3                         [-1, 16, 32, 32]          --\n",
            "├─MaxPool2d: 1-2                         [-1, 16, 16, 16]          --\n",
            "├─Sequential: 1-3                        [-1, 16, 16, 16]          --\n",
            "|    └─Conv2d: 2-4                       [-1, 16, 16, 16]          2,320\n",
            "|    └─BatchNorm2d: 2-5                  [-1, 16, 16, 16]          32\n",
            "|    └─ReLU: 2-6                         [-1, 16, 16, 16]          --\n",
            "├─MaxPool2d: 1-4                         [-1, 16, 8, 8]            --\n",
            "├─Sequential: 1-5                        [-1, 32, 8, 8]            --\n",
            "|    └─Conv2d: 2-7                       [-1, 32, 8, 8]            4,640\n",
            "|    └─BatchNorm2d: 2-8                  [-1, 32, 8, 8]            64\n",
            "|    └─ReLU: 2-9                         [-1, 32, 8, 8]            --\n",
            "├─MaxPool2d: 1-6                         [-1, 32, 4, 4]            --\n",
            "├─Linear: 1-7                            [-1, 50]                  25,650\n",
            "├─Linear: 1-8                            [-1, 50]                  2,550\n",
            "├─Linear: 1-9                            [-1, 10]                  510\n",
            "==========================================================================================\n",
            "Total params: 36,246\n",
            "Trainable params: 36,246\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (M): 1.36\n",
            "==========================================================================================\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 0.34\n",
            "Params size (MB): 0.14\n",
            "Estimated Total Size (MB): 0.49\n",
            "==========================================================================================\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "├─Sequential: 1-1                        [-1, 16, 32, 32]          --\n",
              "|    └─Conv2d: 2-1                       [-1, 16, 32, 32]          448\n",
              "|    └─BatchNorm2d: 2-2                  [-1, 16, 32, 32]          32\n",
              "|    └─ReLU: 2-3                         [-1, 16, 32, 32]          --\n",
              "├─MaxPool2d: 1-2                         [-1, 16, 16, 16]          --\n",
              "├─Sequential: 1-3                        [-1, 16, 16, 16]          --\n",
              "|    └─Conv2d: 2-4                       [-1, 16, 16, 16]          2,320\n",
              "|    └─BatchNorm2d: 2-5                  [-1, 16, 16, 16]          32\n",
              "|    └─ReLU: 2-6                         [-1, 16, 16, 16]          --\n",
              "├─MaxPool2d: 1-4                         [-1, 16, 8, 8]            --\n",
              "├─Sequential: 1-5                        [-1, 32, 8, 8]            --\n",
              "|    └─Conv2d: 2-7                       [-1, 32, 8, 8]            4,640\n",
              "|    └─BatchNorm2d: 2-8                  [-1, 32, 8, 8]            64\n",
              "|    └─ReLU: 2-9                         [-1, 32, 8, 8]            --\n",
              "├─MaxPool2d: 1-6                         [-1, 32, 4, 4]            --\n",
              "├─Linear: 1-7                            [-1, 50]                  25,650\n",
              "├─Linear: 1-8                            [-1, 50]                  2,550\n",
              "├─Linear: 1-9                            [-1, 10]                  510\n",
              "==========================================================================================\n",
              "Total params: 36,246\n",
              "Trainable params: 36,246\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (M): 1.36\n",
              "==========================================================================================\n",
              "Input size (MB): 0.01\n",
              "Forward/backward pass size (MB): 0.34\n",
              "Params size (MB): 0.14\n",
              "Estimated Total Size (MB): 0.49\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To understand why the Convolutional Neural Network (CNN) has fewer parameters but achieves higher accuracy compared to the Multi-Layer Perceptron (MLP) from the previous homewori can consider the following factors:\n",
        "\n",
        "Convolutional Layers, CNNs utilize convolutional layers that are specifically designed for processing grid-like data, such as images. These layers use a small set of learnable filters (kernels) that slide across the input data to capture spatial patterns. Unlike fully connected layers in MLPs, convolutional layers share weights across different spatial locations, significantly reducing the number of parameters. This weight sharing allows CNNS to etticiently capture local patterns and edges in the input.\n",
        "\n",
        "Pooling Layers: CNN architectures often include pooling layers (e.g., max-pooling) that down-sample the spatial dimensions of feature maps. Pooling layers reduce the number of parameters and comouratong complex wnie retaining importancreatures.nis cown-samonne melos in caournethe moscreevancinormation anomakes the nework more ronust to sma variations in Input.\n",
        "\n",
        "Hierarchical Feature Extraction: CNNs are designed to capture hierarchical features in data. The early layers of a CNN detect simple features like edges and corners, while subsequent layers combine these low-level features to recognize more complex patterns and shapes. This hierarchical feature extraction enables CNNs to represent data in a more compact and\n",
        "Informative manner, requiring felter parameters to achieve high accuracy.\n",
        "\n",
        "Translation Invariance: CNN architectures inherently possess translation invariance, which means they can recognize patterns regardless of their position within the input. This property is particularly advantageous for tasks like image classification, where the same object can appear in different locations within an image. By reusing weights across the input, CNNs can effectively learn translation-invariant features.\n",
        "\n",
        "In summary, CNNs are tailored for tasks involving grid-like data and leverage weight sharing, pooling, and hierarchical feature extraction to efficiently capture essential information while keeping the number of parameters low. This efficiency in feature representation and the network's ability to recognize patterns at different levels of abstraction contribute to its higher accuracy despite having fewer parameters compared to MPs"
      ],
      "metadata": {
        "id": "WMmELJJSPGX1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "c. (5 points) Train another CNN with the pool option set to False. What are the differences in terms of accuracy or computation caused by disabling max pooling? What are the effects of pooling operations in CNNs? (This might take some time. Watch a TV show while you're waiting for the results..)"
      ],
      "metadata": {
        "id": "8eb6rNHsobVb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = CNN(pool=False)\n",
        "optimizer = torch.optim.Adam(model2.parameters(), lr=1e-3)\n",
        "best_acc = -np.inf\n",
        "epochs = 10\n",
        "for e in range(1, epochs + 1):\n",
        "    train_loss = train(model2, train_loader, optimizer)\n",
        "    val_loss, val_acc = eval(model2, val_loader)\n",
        "    if val_acc > best_acc:\n",
        "        best_acc = val_acc\n",
        "        best_model2 = model2\n",
        "    print(f\"Epoch: {e} Train Loss: {train_loss} Val Loss: {val_loss} Val Acc: {val_acc}\")"
      ],
      "metadata": {
        "id": "1m-9yG9VAbgE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc9c68f6-5ef0-489c-cdc0-86e118c804c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 229/229 [03:03<00:00,  1.25it/s]\n",
            "100%|██████████| 58/58 [00:17<00:00,  3.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 Train Loss: 1.0621510849543352 Val Loss: 0.5923077000023854 Val Acc: 0.826986076986077\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 229/229 [02:46<00:00,  1.38it/s]\n",
            "100%|██████████| 58/58 [00:13<00:00,  4.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 2 Train Loss: 0.5078498294635007 Val Loss: 0.4920821153105461 Val Acc: 0.8549003549003549\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 229/229 [02:44<00:00,  1.39it/s]\n",
            "100%|██████████| 58/58 [00:13<00:00,  4.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 3 Train Loss: 0.4184380031147667 Val Loss: 0.457595560253236 Val Acc: 0.8650696150696151\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 229/229 [02:46<00:00,  1.38it/s]\n",
            "100%|██████████| 58/58 [00:13<00:00,  4.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 4 Train Loss: 0.3603788178682673 Val Loss: 0.43692321938274664 Val Acc: 0.8732596232596233\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 229/229 [02:47<00:00,  1.37it/s]\n",
            "100%|██████████| 58/58 [00:15<00:00,  3.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 5 Train Loss: 0.3239931190283914 Val Loss: 0.4283116106091384 Val Acc: 0.8760578760578761\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 229/229 [02:46<00:00,  1.37it/s]\n",
            "100%|██████████| 58/58 [00:13<00:00,  4.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 6 Train Loss: 0.2801510897871476 Val Loss: 0.42703135630129596 Val Acc: 0.8796751296751297\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 229/229 [02:47<00:00,  1.36it/s]\n",
            "100%|██████████| 58/58 [00:16<00:00,  3.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 7 Train Loss: 0.25115929920868035 Val Loss: 0.4293810712113069 Val Acc: 0.8783783783783784\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 229/229 [02:47<00:00,  1.37it/s]\n",
            "100%|██████████| 58/58 [00:13<00:00,  4.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 8 Train Loss: 0.21606723618897936 Val Loss: 0.45245430674866643 Val Acc: 0.8746246246246246\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 229/229 [02:45<00:00,  1.38it/s]\n",
            "100%|██████████| 58/58 [00:13<00:00,  4.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 9 Train Loss: 0.1930729129533395 Val Loss: 0.4546862811972917 Val Acc: 0.878992628992629\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 229/229 [02:45<00:00,  1.38it/s]\n",
            "100%|██████████| 58/58 [00:16<00:00,  3.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 Train Loss: 0.17116291668800332 Val Loss: 0.4716499082026116 Val Acc: 0.8777641277641277\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_, test_acc = eval(best_model2, test_loader)\n",
        "print(test_acc)"
      ],
      "metadata": {
        "id": "13gIhnYVAbgQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1998dc9d-ad82-4268-b0d6-756ebf9a044e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 102/102 [00:29<00:00,  3.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8574830977258758\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary(best_model2, (3, 32, 32))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S527kL7PUJiF",
        "outputId": "2c9429d8-eba7-4475-880c-f889987cdfa6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==========================================================================================\n",
            "Layer (type:depth-idx)                   Output Shape              Param #\n",
            "==========================================================================================\n",
            "├─Sequential: 1-1                        [-1, 16, 32, 32]          --\n",
            "|    └─Conv2d: 2-1                       [-1, 16, 32, 32]          448\n",
            "|    └─BatchNorm2d: 2-2                  [-1, 16, 32, 32]          32\n",
            "|    └─ReLU: 2-3                         [-1, 16, 32, 32]          --\n",
            "├─Sequential: 1-2                        [-1, 16, 32, 32]          --\n",
            "|    └─Conv2d: 2-4                       [-1, 16, 32, 32]          2,320\n",
            "|    └─BatchNorm2d: 2-5                  [-1, 16, 32, 32]          32\n",
            "|    └─ReLU: 2-6                         [-1, 16, 32, 32]          --\n",
            "├─Sequential: 1-3                        [-1, 32, 32, 32]          --\n",
            "|    └─Conv2d: 2-7                       [-1, 32, 32, 32]          4,640\n",
            "|    └─BatchNorm2d: 2-8                  [-1, 32, 32, 32]          64\n",
            "|    └─ReLU: 2-9                         [-1, 32, 32, 32]          --\n",
            "├─Linear: 1-4                            [-1, 50]                  1,638,450\n",
            "├─Linear: 1-5                            [-1, 50]                  2,550\n",
            "├─Linear: 1-6                            [-1, 10]                  510\n",
            "==========================================================================================\n",
            "Total params: 1,649,046\n",
            "Trainable params: 1,649,046\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (M): 9.17\n",
            "==========================================================================================\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 1.00\n",
            "Params size (MB): 6.29\n",
            "Estimated Total Size (MB): 7.30\n",
            "==========================================================================================\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "├─Sequential: 1-1                        [-1, 16, 32, 32]          --\n",
              "|    └─Conv2d: 2-1                       [-1, 16, 32, 32]          448\n",
              "|    └─BatchNorm2d: 2-2                  [-1, 16, 32, 32]          32\n",
              "|    └─ReLU: 2-3                         [-1, 16, 32, 32]          --\n",
              "├─Sequential: 1-2                        [-1, 16, 32, 32]          --\n",
              "|    └─Conv2d: 2-4                       [-1, 16, 32, 32]          2,320\n",
              "|    └─BatchNorm2d: 2-5                  [-1, 16, 32, 32]          32\n",
              "|    └─ReLU: 2-6                         [-1, 16, 32, 32]          --\n",
              "├─Sequential: 1-3                        [-1, 32, 32, 32]          --\n",
              "|    └─Conv2d: 2-7                       [-1, 32, 32, 32]          4,640\n",
              "|    └─BatchNorm2d: 2-8                  [-1, 32, 32, 32]          64\n",
              "|    └─ReLU: 2-9                         [-1, 32, 32, 32]          --\n",
              "├─Linear: 1-4                            [-1, 50]                  1,638,450\n",
              "├─Linear: 1-5                            [-1, 50]                  2,550\n",
              "├─Linear: 1-6                            [-1, 10]                  510\n",
              "==========================================================================================\n",
              "Total params: 1,649,046\n",
              "Trainable params: 1,649,046\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (M): 9.17\n",
              "==========================================================================================\n",
              "Input size (MB): 0.01\n",
              "Forward/backward pass size (MB): 1.00\n",
              "Params size (MB): 6.29\n",
              "Estimated Total Size (MB): 7.30\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Disabling max pooling in a CNN has dual consequences. Firstly, the spatial resolution of feature maps remains higher, preserving fine-grained spatial details but potentially making the model more sensitive to small translations. Secondly, it leads to an increase in the number of parameters in the subsequent fully connected layers, possibly raising the risk of overfitting. The effects of pooling operations in CNNs are multifold: pooling facilitates downsampling, contributing to translation invariance and noise reduction. It also enhances the receptive field of neurons, allowing them to capture information from a larger portion of the input. The decision to use or omit max pooling involves a trade-off between maintaining spatial information and managing computation, often necessitating experimentation to assess the impact on accuracy and efficiency."
      ],
      "metadata": {
        "id": "v_II4Ek-b4kX"
      }
    }
  ]
}